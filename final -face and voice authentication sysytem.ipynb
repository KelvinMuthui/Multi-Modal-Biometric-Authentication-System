{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a47a9202",
   "metadata": {},
   "source": [
    "# VOICE AND FACE AUTHENTICATION SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba122a0",
   "metadata": {},
   "source": [
    "### RUN THE CELL ONE BY ONE AFTER READING INSTRUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c51a4",
   "metadata": {},
   "source": [
    "## Please install necessary library required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea9fb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "\n",
    "import pyaudio\n",
    "from IPython.display import Audio, display, clear_output\n",
    "import wave\n",
    "from scipy.io.wavfile import read\n",
    "#from sklearn.mixture import GMM \n",
    "from sklearn.mixture import GaussianMixture \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "import face_recognition\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328e29a2",
   "metadata": {},
   "source": [
    "# Audio processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357b696c",
   "metadata": {},
   "source": [
    "### -After installling all the necessary library pls run the below cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd80cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_delta(array):\n",
    "    rows, cols = array.shape\n",
    "    deltas = np.zeros((rows, cols))\n",
    "    N = 2\n",
    "    for i in range(rows):\n",
    "        index = []\n",
    "        j = 1\n",
    "        while len(index) < 2 and j < N+1:\n",
    "            if i-j >= 0:\n",
    "                index.append(i-j)\n",
    "            if i+j < rows:\n",
    "                index.append(i+j)\n",
    "            j+=1\n",
    "        if len(index) == 2:\n",
    "            deltas[i] = (array[index[1]] - array[index[0]]) / (2*N)\n",
    "        elif len(index) == 1:\n",
    "            deltas[i] = (array[index[0]] - array[i]) / N\n",
    "    return deltas\n",
    "\n",
    "\n",
    "#convert audio to mfcc features\n",
    "def extract_features(audio, rate):    \n",
    "    mfcc_feat = mfcc.mfcc(audio, rate, 0.025, 0.01, 12, appendEnergy=True, nfft=2048)\n",
    "    mfcc_feat = preprocessing.scale(mfcc_feat)\n",
    "    delta = calculate_delta(mfcc_feat)\n",
    "\n",
    "    #combining both mfcc features and delta\n",
    "    combined = np.hstack((mfcc_feat, delta)) \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e4a399",
   "metadata": {},
   "source": [
    "# Registering  New User voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa3e681",
   "metadata": {},
   "source": [
    "### Run the below code for registering new voice of the person .\n",
    "\n",
    "### WARNING:- RECORD IN SILENCE\n",
    "\n",
    "\n",
    "##### -------------------- follow steps below --------------------------------------------\n",
    "\n",
    "#### - RUN THE CODE \n",
    "#### - ENTER  YOUR NAME \n",
    "#### - SPEAK HELLO COMPUTER WHEN RECORDING\n",
    "#### - SPEAK SAME WORD 2 TIMES MORE\n",
    "#### - NOW YOUR VOICE REGISTERED \n",
    "\n",
    "#### - REGISTER THE 2 OR 3 PERSON VOICE \n",
    "#### - NOW YOUR VOICE REGISTERED \n",
    "\n",
    "###### -----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## TIPS:- register in silence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee8266",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Cell 2: Import all dependencies\n",
    "import os\n",
    "import time\n",
    "import wave\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pyaudio\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from IPython.display import clear_output\n",
    "from scipy.io import wavfile\n",
    "import python_speech_features\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Cell 3: Configuration\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1  # Changed to 1 channel for better compatibility\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 3\n",
    "PHRASE = \"HELLO COMPUTER\"\n",
    "\n",
    "# Cell 4: Audio recording function\n",
    "def record_audio_sample():\n",
    "    audio = pyaudio.PyAudio()\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                       rate=RATE, input=True,\n",
    "                       frames_per_buffer=CHUNK)\n",
    "    \n",
    "    print(\"Recording...\")\n",
    "    frames = []\n",
    "    \n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "        frames.append(data)\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "    return b''.join(frames)\n",
    "\n",
    "# Cell 5: Feature extraction (fixed version)\n",
    "def extract_features(audio_path):\n",
    "    try:\n",
    "        (rate, sig) = wavfile.read(audio_path)\n",
    "        mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13,\n",
    "                                                nfilt=26, nfft=2048, lowfreq=0, highfreq=None, preemph=0.97,\n",
    "                                                ceplifter=22, appendEnergy=True)\n",
    "        return mfcc_feat\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Cell 6: Main registration function\n",
    "def register_voice():\n",
    "    name = input(\"Enter your name: \").strip().lower()\n",
    "    os.makedirs(\"./voice_database\", exist_ok=True)\n",
    "    os.makedirs(\"./gmm_models\", exist_ok=True)\n",
    "    \n",
    "    source = \"./voice_database/\" + name\n",
    "    os.makedirs(source, exist_ok=True)\n",
    "    \n",
    "    for i in range(3):\n",
    "        # Countdown for first sample\n",
    "        if i == 0:\n",
    "            for j in range(3, 0, -1):\n",
    "                clear_output(wait=True)\n",
    "                print(f\"Speak '{PHRASE}' in {j} seconds...\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # Record audio\n",
    "        audio_data = record_audio_sample()\n",
    "        \n",
    "        # Save recording\n",
    "        filename = f\"{source}/{i+1}.wav\"\n",
    "        with wave.open(filename, 'wb') as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(pyaudio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(audio_data)\n",
    "        \n",
    "        # Verify recording\n",
    "        try:\n",
    "            with wave.open(filename, 'rb') as wf:\n",
    "                if wf.getnframes() == 0:\n",
    "                    print(\"Empty recording - please try again\")\n",
    "                    return False\n",
    "        except:\n",
    "            print(\"Invalid recording - please try again\")\n",
    "            return False\n",
    "    \n",
    "    # Process recordings\n",
    "    features = np.array([])\n",
    "    for i in range(1, 4):\n",
    "        path = f\"{source}/{i}.wav\"\n",
    "        vector = extract_features(path)\n",
    "        \n",
    "        if vector is None:\n",
    "            print(f\"Failed to process {path}\")\n",
    "            return False\n",
    "            \n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "    \n",
    "    # Train model\n",
    "    gmm = GaussianMixture(n_components=16, max_iter=200, covariance_type='diag', n_init=3)\n",
    "    gmm.fit(features)\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f\"./gmm_models/{name}.gmm\"\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(gmm, f)\n",
    "    \n",
    "    print(f\"\\nRegistration successful for {name}!\")\n",
    "    return True\n",
    "\n",
    "# Cell 7: Run registration\n",
    "register_voice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99a395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de9fe487",
   "metadata": {},
   "source": [
    "# Registering a New User face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd6fda7",
   "metadata": {},
   "source": [
    "###  Run the below code for registering new face of the person .\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### --------------------------------------------------------follow steps below--------------------------------------------------------------------------------------- \n",
    "\n",
    "#### - RUN THE CODE \n",
    "#### - ENTER  YOUR NAME \n",
    "#### - IT START RECORDING \n",
    "#### - PRESS S TO SAVE IMAGE \n",
    "#### - AFTER THE MESSAGE SUCCESSFUL PRINTED IN BELOW CELL\n",
    "#### - PRESS Q TO EXIT\n",
    " \n",
    "#### --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## TIPS:- register 2 to 3 image to help the model to classify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Create a directory to store captured images\n",
    "dir_name = 'captured_images'\n",
    "if not os.path.exists(dir_name):\n",
    "    os.makedirs(dir_name)\n",
    "\n",
    "# Get name of the person to capture images\n",
    "name = input(\"Enter your name: \")\n",
    "\n",
    "# Create a directory with the name of the person\n",
    "person_dir = os.path.join(dir_name, name)\n",
    "if not os.path.exists(person_dir):\n",
    "    os.makedirs(person_dir)\n",
    "\n",
    "# Initialize the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set the width and height of the capture window\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "# Define the codec and create a VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "# Capture frames continuously\n",
    "while True:\n",
    "    # Capture a frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Display instructions in the frame\n",
    "    cv2.putText(frame, \"Press 'q' to exit\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Press 's' to save image\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Exit the camera if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Save the image if 's' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        # Generate a unique filename for the image\n",
    "        filename = os.path.join(person_dir, name + \"_\" + str(len(os.listdir(person_dir))+1) + \".jpg\")\n",
    "\n",
    "        # Save the image\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(\"Image saved successfully!\")\n",
    "\n",
    "# Release the webcam and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401325d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd73a13f",
   "metadata": {},
   "source": [
    "# Automatically add array of face encodings and there name and store it in a empty list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f50ab82",
   "metadata": {},
   "source": [
    "### just run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dee765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import pickle\n",
    "\n",
    "def save_user_face_encoding(user_folder_path):\n",
    "    image_files = [f for f in os.listdir(user_folder_path) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {user_folder_path}\")\n",
    "        return False\n",
    "\n",
    "    # For better accuracy, you can encode multiple images and average or keep all encodings\n",
    "    encodings = []\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(user_folder_path, img_file)\n",
    "        image = face_recognition.load_image_file(img_path)\n",
    "        face_encs = face_recognition.face_encodings(image)\n",
    "        if face_encs:\n",
    "            encodings.append(face_encs[0])\n",
    "        else:\n",
    "            print(f\"No face found in {img_path}\")\n",
    "\n",
    "    if not encodings:\n",
    "        print(f\"No valid face encodings found for {user_folder_path}\")\n",
    "        return False\n",
    "\n",
    "    # For simplicity, take the first encoding or average encodings\n",
    "    # Here we take the first encoding\n",
    "    user_encoding = encodings[0]\n",
    "\n",
    "    # Save encoding to pickle in user folder\n",
    "    pickle_path = os.path.join(user_folder_path, 'face_encoding.pkl')\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(user_encoding, f)\n",
    "\n",
    "    print(f\"Saved face encoding for user at {pickle_path}\")\n",
    "    return True\n",
    "\n",
    "# Example usage:\n",
    "base_path = 'captured_images'\n",
    "for user_name in os.listdir(base_path):\n",
    "    user_path = os.path.join(base_path, user_name)\n",
    "    if os.path.isdir(user_path):\n",
    "        save_user_face_encoding(user_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c4e457",
   "metadata": {},
   "source": [
    "# ----------------------------VOICE RECOGNITION---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aff2538",
   "metadata": {},
   "source": [
    "### - JUST SPEAK SAME WORD YOU REGISTERED IN SAME PITCH TO RECOGNISE YOUR VOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d442f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import python_speech_features\n",
    "\n",
    "# Configuration parameters (match with registration)\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1  # Changed to 1 to match registration\n",
    "RATE = 44100\n",
    "CHUNK = 1024\n",
    "RECORD_SECONDS = 3\n",
    "FILENAME = \"./test.wav\"\n",
    "\n",
    "def extract_features(audio_path):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from a WAV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        (rate, sig) = wavfile.read(audio_path)\n",
    "        mfcc_feat = python_speech_features.mfcc(sig, rate, winlen=0.025, winstep=0.01, numcep=13,\n",
    "                                                nfilt=26, nfft=2048, lowfreq=0, highfreq=None, preemph=0.97,\n",
    "                                                ceplifter=22, appendEnergy=True)\n",
    "        return mfcc_feat\n",
    "    except Exception as e:\n",
    "        print(f\"Feature extraction failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def recognize_voice():\n",
    "    \"\"\"\n",
    "    Record audio from microphone and identify speaker by comparing with saved GMM models.\n",
    "    \"\"\"\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Start recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                        rate=RATE, input=True,\n",
    "                        frames_per_buffer=CHUNK)\n",
    "\n",
    "    print(\"Recording... please say 'HELLO COMPUTER' for authentication\")\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK, exception_on_overflow=False)\n",
    "        frames.append(data)\n",
    "    print(\"Finished recording.\")\n",
    "\n",
    "    # Stop recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded data as a WAV file\n",
    "    with wave.open(FILENAME, 'wb') as waveFile:\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "\n",
    "    # Load GMM models\n",
    "    modelpath = \"./gmm_models/\"\n",
    "    gmm_files = [os.path.join(modelpath, fname) for fname in os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    if len(gmm_files) == 0:\n",
    "        print(\"No users in the database. Please register first.\")\n",
    "        return None\n",
    "\n",
    "    models = [pickle.load(open(fname, 'rb')) for fname in gmm_files]\n",
    "    speakers = [os.path.splitext(os.path.basename(fname))[0] for fname in gmm_files]\n",
    "\n",
    "    # Extract features from the recorded audio\n",
    "    vector = extract_features(FILENAME)\n",
    "    if vector is None:\n",
    "        print(\"Could not extract features from the audio.\")\n",
    "        return None\n",
    "\n",
    "    log_likelihood = np.zeros(len(models))\n",
    "\n",
    "    # Compute log likelihood for each model\n",
    "    for i, gmm in enumerate(models):\n",
    "        scores = gmm.score(vector)\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    # Identify the speaker with the highest score\n",
    "    pred_index = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred_index]\n",
    "\n",
    "    print(f\"Recognized as: {identity}\")\n",
    "    return identity\n",
    "\n",
    "# Run the recognition\n",
    "recognized_user = recognize_voice()\n",
    "print(f\"Authenticated user: {recognized_user}\")\n",
    "\n",
    "\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67863fd",
   "metadata": {},
   "source": [
    "# ----------------------------FACE AND VOICE AUTHENTICATION--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1805fe25",
   "metadata": {},
   "source": [
    "#### - KEEP YOUR FACE INFRONT OF THE CAMERA\n",
    "### -------------------------------------THE RESULT WILL SHOW AS BELOW-----------------------------------\n",
    "#### - IF FACE MATCHES WITH VOICE  --Authenticaation successful !welcome-------\n",
    "#### - IF VOICE IDENTITY AND FACE IDENTIY IS DIFFERENT -----Voice identity not matching with face !Try again....\n",
    "#### - IF VOICE IDENTITY== UKNOWN     ------------Voice not recognized , !Try again.....\n",
    "#### - IF FACE IDENTITY == UKNOWN      -------------\" Face not registered,! Unsuccessful\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc52235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def load_all_face_encodings(base_path='captured_images'):\n",
    "    \"\"\"\n",
    "    Loads face encodings and user names from individual pickle files stored in user folders.\n",
    "    \"\"\"\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        print(f\"Error: Base path '{base_path}' does not exist.\")\n",
    "        return known_face_encodings, known_face_names\n",
    "\n",
    "    for user_name in os.listdir(base_path):\n",
    "        user_path = os.path.join(base_path, user_name)\n",
    "        if not os.path.isdir(user_path):\n",
    "            continue  # Skip files, only process directories\n",
    "\n",
    "        pickle_path = os.path.join(user_path, 'face_encoding.pkl')\n",
    "        if os.path.exists(pickle_path):\n",
    "            try:\n",
    "                with open(pickle_path, 'rb') as f:\n",
    "                    encoding = pickle.load(f)\n",
    "                known_face_encodings.append(encoding)\n",
    "                known_face_names.append(user_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load encoding for user '{user_name}': {e}\")\n",
    "        else:\n",
    "            print(f\"Warning: No encoding pickle file found for user '{user_name}' in '{user_path}'\")\n",
    "\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "# === Load all known face encodings and names from user folders ===\n",
    "known_face_encodings, known_face_names = load_all_face_encodings()\n",
    "\n",
    "# Identity from voice authentication step (replace with actual voice-authenticated username)\n",
    "\n",
    "identity = recognize_voice()\n",
    "print(f\"Voice authentication recognized user: {identity}\")\n",
    "\n",
    "print(\"Keep your face in front of the camera\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "time.sleep(1.0)\n",
    "process_this_frame = True\n",
    "\n",
    "timeout_seconds = 20  # Run for 20 seconds\n",
    "start_time = time.time()\n",
    "\n",
    "authenticated = False  # Flag to track if authentication succeeded\n",
    "last_frame = None     # To store last frame for display\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        elapsed = time.time() - start_time\n",
    "        if elapsed > timeout_seconds:\n",
    "            print(\"Timeout reached. Ending authentication.\")\n",
    "            break\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        face_names = []\n",
    "        face_locations = []\n",
    "\n",
    "        if process_this_frame:\n",
    "            face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "\n",
    "            if len(face_locations) == 1:\n",
    "                face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "                for face_encoding in face_encodings:\n",
    "                    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "                    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                    if matches[best_match_index]:\n",
    "                        facename = known_face_names[best_match_index]\n",
    "                    else:\n",
    "                        facename = \"Unknown\"\n",
    "\n",
    "                    face_names.append(facename)\n",
    "\n",
    "                    if facename == identity:\n",
    "                        authenticated = True\n",
    "\n",
    "            elif len(face_locations) > 1:\n",
    "                print(\"More than one face found. Please show only one face.\")\n",
    "\n",
    "        process_this_frame = not process_this_frame\n",
    "\n",
    "        # Draw rectangles and labels on frame\n",
    "        for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "            top *= 4\n",
    "            right *= 4\n",
    "            bottom *= 4\n",
    "            left *= 4\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 0), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "            if name == identity:\n",
    "                text = f\"{name} Authentication successful! Welcome.\"\n",
    "                color = (0, 255, 0)\n",
    "            elif name == \"Unknown\":\n",
    "                text = \"Face not registered! Unsuccessful.\"\n",
    "                color = (0, 0, 255)\n",
    "            elif identity == \"unknown\":\n",
    "                text = \"Voice not recognized! Try again.\"\n",
    "                color = (0, 0, 255)\n",
    "            else:\n",
    "                text = \"Voice and face identity mismatch! Try again.\"\n",
    "                color = (0, 0, 255)\n",
    "\n",
    "            cv2.putText(frame, text, (left + 6, bottom - 6), font, 0.5, color, 1)\n",
    "\n",
    "        last_frame = frame.copy()\n",
    "\n",
    "        # Display live frame in notebook\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        clear_output(wait=True)\n",
    "        plt.imshow(rgb_frame)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        time.sleep(0.1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted by user\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    # Avoid cv2.destroyAllWindows() to prevent errors in some environments\n",
    "\n",
    "# After loop ends, print final result below the cell\n",
    "if authenticated:\n",
    "    print(f\"\\n‚úÖ Authentication successful for user: {identity}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå Authentication failed for user: {identity}\")\n",
    "\n",
    "# Optionally show the last frame with the label\n",
    "if last_frame is not None:\n",
    "    rgb_last_frame = cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(rgb_last_frame)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Last captured frame\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "               \n",
    "\n",
    "\n",
    "                   \n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4751d1c-77de-4e97-be21-54edfdb6ce79",
   "metadata": {},
   "source": [
    "# -------------------------------Admin Panel------------------------------\n",
    "\n",
    "## - Facilitates Create, Read, Update, Delete operations\n",
    "\n",
    "## - Demonstrates User Authentication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453b0b32-7631-4134-8ede-9d7be5804673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c4240f9b8649ac95703592d9fdb8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='üîê Admin Panel for Biometric Authentication System'), HBox(children=(Text(value='',‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ========== Imports ==========\n",
    "import os, time, cv2, pickle\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from scipy.io.wavfile import write, read\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "import pickle\n",
    "import python_speech_features\n",
    "from scipy.io import wavfile\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import VBox, HBox, Button, Dropdown, Text, Output, Label\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# ========== Paths ==========\n",
    "image_path = \"./captured_images\"\n",
    "voice_data_path = \"./voice_database\"\n",
    "\n",
    "# ========== Widgets ==========\n",
    "output = Output()\n",
    "new_user_text = Text(placeholder='Enter new username...')\n",
    "user_dropdown = Dropdown(description='Users:')\n",
    "add_user_button = Button(description=\"‚ûï Add\")\n",
    "delete_user_button = Button(description=\"‚ùå Delete\")\n",
    "update_user_button = Button(description=\"üîÑ Update\")\n",
    "view_user_button = Button(description=\"üëÅÔ∏è View\")\n",
    "refresh_button = Button(description=\"üîÅ Refresh\")\n",
    "authenticate_button = Button(description=\"üîê Authenticate\")\n",
    "\n",
    "# ========== Utilities ==========\n",
    "\n",
    "def countdown(seconds):\n",
    "    for i in range(seconds, 0, -1):\n",
    "        print(f\"‚è≥ Recording in {i}...\")\n",
    "        time.sleep(1)\n",
    "\n",
    "def get_user_list():\n",
    "    return sorted(os.listdir(image_path)) if os.path.exists(image_path) else []\n",
    "\n",
    "def save_user_face_encoding(user_folder_path):\n",
    "    image_files = [f for f in os.listdir(user_folder_path) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    encodings = []\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(user_folder_path, image_file)\n",
    "        img = face_recognition.load_image_file(img_path)\n",
    "        encoding = face_recognition.face_encodings(img)\n",
    "        if encoding:\n",
    "            encodings.append(encoding[0])\n",
    "    if encodings:\n",
    "        avg = np.mean(encodings, axis=0)\n",
    "        with open(os.path.join(user_folder_path, 'face_encoding.pkl'), 'wb') as f:\n",
    "            pickle.dump(avg, f)\n",
    "        print(\"‚úÖ Face encoding saved.\")\n",
    "    else:\n",
    "        print(\"‚ùå No valid encodings found.\")\n",
    "\n",
    "def register_voice(name):\n",
    "    user_voice_path = os.path.join(voice_data_path, name)\n",
    "    os.makedirs(user_voice_path, exist_ok=True)\n",
    "    for i in range(1, 4):\n",
    "        print(f\"üéôÔ∏è Say 'hello computer' sample {i}/3\")\n",
    "        countdown(3)\n",
    "        fs = 44100\n",
    "        duration = 3\n",
    "        voice = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "        sd.wait()\n",
    "        file_path = os.path.join(user_voice_path, f\"hello_computer_{i}.wav\")\n",
    "        write(file_path, fs, voice)\n",
    "        print(f\"‚úÖ Saved voice to {file_path}\")\n",
    "\n",
    "def compare_voices(file1, file2):\n",
    "    try:\n",
    "        _, data1 = read(file1)\n",
    "        _, data2 = read(file2)\n",
    "        min_len = min(len(data1), len(data2))\n",
    "        if min_len == 0: return 1.0\n",
    "        return np.linalg.norm(data1[:min_len] - data2[:min_len]) / min_len\n",
    "    except:\n",
    "        return 1.0\n",
    "\n",
    "def recognize_voice(selected_user):\n",
    "    \n",
    "    \"\"\"Authenticate user using GMM model comparison\"\"\"\n",
    "    # Record new voice sample\n",
    "    fs = 44100\n",
    "    duration = 3\n",
    "    countdown(3)\n",
    "    print(\"üî¥ Recording...\")\n",
    "    voice_data = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()\n",
    "    temp_path = \"./temp_voice.wav\"\n",
    "    write(temp_path, fs, voice_data)\n",
    "\n",
    "    # Load the target user's GMM model\n",
    "    gmm_path = f\"./gmm_models/{selected_user}.gmm\"\n",
    "    if not os.path.exists(gmm_path):\n",
    "        print(f\"‚ùå No GMM model found for {selected_user}\")\n",
    "        os.remove(temp_path)\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        # Extract features\n",
    "        (rate, sig) = wavfile.read(temp_path)\n",
    "        mfcc_feat = python_speech_features.mfcc(\n",
    "            sig, rate, \n",
    "            winlen=0.025, winstep=0.01, numcep=13,\n",
    "            nfilt=26, nfft=2048, lowfreq=0, \n",
    "            highfreq=None, preemph=0.97,\n",
    "            ceplifter=22, appendEnergy=True\n",
    "        )\n",
    "\n",
    "        # Load GMM model\n",
    "        with open(gmm_path, 'rb') as gmm_file:\n",
    "            gmm = pickle.load(gmm_file)\n",
    "\n",
    "        # Calculate log likelihood\n",
    "        scores = gmm.score(mfcc_feat)\n",
    "        log_likelihood = scores.sum()\n",
    "        print(f\"üîç Voice match score for {selected_user}: {log_likelihood:.2f}\")\n",
    "\n",
    "        # Threshold for acceptance (adjust based on your testing)\n",
    "        threshold = -60  # Typical range: -10 to -30\n",
    "        is_match = log_likelihood > threshold\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(temp_path)\n",
    "        \n",
    "        return is_match\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error during voice recognition: {str(e)}\")\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "        return False\n",
    "        \n",
    "\n",
    "def load_all_face_encodings(base_path='captured_images'):\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    if not os.path.exists(base_path): return known_face_encodings, known_face_names\n",
    "    for user_name in os.listdir(base_path):\n",
    "        pkl_path = os.path.join(base_path, user_name, 'face_encoding.pkl')\n",
    "        if os.path.exists(pkl_path):\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                known_face_encodings.append(pickle.load(f))\n",
    "                known_face_names.append(user_name)\n",
    "    return known_face_encodings, known_face_names\n",
    "\n",
    "# ========== Button Functions ==========\n",
    "\n",
    "def on_add_user(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        name = new_user_text.value.strip()\n",
    "        if not name:\n",
    "            print(\"‚ùå Please enter a name.\")\n",
    "            return\n",
    "        print(f\"üë§ Registering {name}\")\n",
    "        img_dir = os.path.join(image_path, name)\n",
    "        os.makedirs(img_dir, exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        for i in range(3):\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                file_path = os.path.join(img_dir, f\"{name}_{i+1}.jpg\")\n",
    "                cv2.imwrite(file_path, frame)\n",
    "                print(f\"üì∑ Image {i+1}/3 saved.\")\n",
    "                time.sleep(1)\n",
    "        cap.release()\n",
    "\n",
    "        register_voice(name)\n",
    "        save_user_face_encoding(img_dir)\n",
    "        train_gmm_model(name)\n",
    "        refresh_user_list()\n",
    "        print(\"‚úÖ User registered.\")\n",
    "\n",
    "def on_delete_user(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        name = user_dropdown.value\n",
    "        if not name:\n",
    "            print(\"‚ùå Select user to delete.\")\n",
    "            return\n",
    "        img_dir = os.path.join(image_path, name)\n",
    "        voice_dir = os.path.join(voice_data_path, name)\n",
    "        for path in [img_dir, voice_dir]:\n",
    "            if os.path.exists(path):\n",
    "                for f in os.listdir(path):\n",
    "                    os.remove(os.path.join(path, f))\n",
    "                os.rmdir(path)\n",
    "        refresh_user_list()\n",
    "        print(f\"üóëÔ∏è Deleted {name}.\")\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "def on_view_user(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        name = user_dropdown.value\n",
    "        if not name:\n",
    "            print(\"‚ùå No user selected.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üëÅÔ∏è Viewing data for: {name}\")\n",
    "        \n",
    "        # === Show face images ===\n",
    "        img_dir = os.path.join(image_path, name)\n",
    "        if os.path.exists(img_dir):\n",
    "            image_files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png'))])\n",
    "            if image_files:\n",
    "                print(\"üñºÔ∏è Face Images:\")\n",
    "                for file in image_files:\n",
    "                    img = cv2.imread(os.path.join(img_dir, file))\n",
    "                    rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    plt.imshow(rgb)\n",
    "                    plt.axis('off')\n",
    "                    plt.title(file)\n",
    "                    plt.show()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No face images found.\")\n",
    "        else:\n",
    "            print(\"‚ùå Face image folder not found.\")\n",
    "\n",
    "        # === Show voice samples ===\n",
    "        voice_dir = os.path.join(voice_data_path, name)\n",
    "        if os.path.exists(voice_dir):\n",
    "            wav_files = sorted([f for f in os.listdir(voice_dir) if f.lower().endswith('.wav')])\n",
    "            if wav_files:\n",
    "                print(\"\\nüéß Voice Samples:\")\n",
    "                for file in wav_files:\n",
    "                    full_path = os.path.join(voice_dir, file)\n",
    "                    print(f\"üîä {file}\")\n",
    "                    display(Audio(full_path, autoplay=False))\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No voice samples found.\")\n",
    "        else:\n",
    "            print(\"‚ùå Voice data folder not found.\")\n",
    "\n",
    "\n",
    "def on_update_user(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        name = user_dropdown.value\n",
    "        if not name:\n",
    "            print(\"‚ùå Please select a user to update.\")\n",
    "            return\n",
    "\n",
    "        print(f\"üîß Updating user: {name}\")\n",
    "\n",
    "        # Re-capture images\n",
    "        user_image_dir = os.path.join(image_path, name)\n",
    "        os.makedirs(user_image_dir, exist_ok=True)\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        count = 0\n",
    "        while count < 3:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"‚ùå Failed to capture image from camera.\")\n",
    "                break\n",
    "            img_path = os.path.join(user_image_dir, f\"{name}_{count+1}.jpg\")\n",
    "            cv2.imwrite(img_path, frame)\n",
    "            print(\"üì∏ Image updated.\")\n",
    "            count += 1\n",
    "            time.sleep(1)\n",
    "        cap.release()\n",
    "\n",
    "        # Save face encoding\n",
    "        save_user_face_encoding(user_image_dir)\n",
    "        \n",
    "\n",
    "        # Re-record voice samples (3 times with countdown)\n",
    "        user_voice_dir = os.path.join(voice_data_path, name)\n",
    "        os.makedirs(user_voice_dir, exist_ok=True)\n",
    "\n",
    "        fs = 44100\n",
    "        duration = 3\n",
    "        for i in range(3):\n",
    "            print(f\"\\nüéôÔ∏è Preparing voice sample {i+1}/3...\")\n",
    "            for j in reversed(range(1, 4)):\n",
    "                print(f\"‚è≥ Recording in {j}...\")\n",
    "                time.sleep(1)\n",
    "            print(\"üî¥ Recording...\")\n",
    "            voice_data = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "            sd.wait()\n",
    "            voice_path = os.path.join(user_voice_dir, f\"hello_computer_{i+1}.wav\")\n",
    "            write(voice_path, fs, voice_data)\n",
    "            print(f\"‚úÖ Saved: {voice_path}\")\n",
    "\n",
    "            train_gmm_model(name)\n",
    "        print(f\"\\n‚úÖ Update complete for user: {name}\")\n",
    "\n",
    "\n",
    "def refresh_user_list(b=None):\n",
    "    output.clear_output()  # Clears the output area\n",
    "\n",
    "    # Clear the dropdown and text field\n",
    "    user_dropdown.options = get_user_list()\n",
    "    user_dropdown.value = None\n",
    "    new_user_text.value = ''\n",
    "    \n",
    "\n",
    "def train_gmm_model(user_name, n_components=16):\n",
    "    \n",
    "    voice_dir = os.path.join(voice_data_path, user_name)\n",
    "    features = []\n",
    "\n",
    "    for file in os.listdir(voice_dir):\n",
    "        if file.endswith(\".wav\"):\n",
    "            filepath = os.path.join(voice_dir, file)\n",
    "            try:\n",
    "                (rate, sig) = wavfile.read(filepath)\n",
    "                mfcc_feat = python_speech_features.mfcc(\n",
    "                    sig, rate, \n",
    "                    winlen=0.025, winstep=0.01, numcep=13,\n",
    "                    nfilt=26, nfft=2048, lowfreq=0,\n",
    "                    highfreq=None, preemph=0.97,\n",
    "                    ceplifter=22, appendEnergy=True\n",
    "                )\n",
    "                features.append(mfcc_feat)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing {filepath}: {e}\")\n",
    "\n",
    "    if not features:\n",
    "        print(f\"‚ùå No valid voice files to train GMM for {user_name}\")\n",
    "        return\n",
    "\n",
    "    X = np.vstack(features)\n",
    "    gmm = GaussianMixture(n_components=n_components, covariance_type='diag', n_init=3)\n",
    "    gmm.fit(X)\n",
    "\n",
    "    os.makedirs(\"./gmm_models\", exist_ok=True)\n",
    "    with open(f\"./gmm_models/{user_name}.gmm\", 'wb') as gmm_file:\n",
    "        pickle.dump(gmm, gmm_file)\n",
    "    print(f\"‚úÖ GMM model saved for {user_name}\")\n",
    "\n",
    "\n",
    "\n",
    "def authenticate_user(b):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        selected_user = user_dropdown.value\n",
    "        if not selected_user:\n",
    "            print(\"‚ùå Please select a user from the dropdown.\")\n",
    "            return\n",
    "        print(f\"üéôÔ∏è Starting authentication for: {selected_user}\")\n",
    "        known_face_encodings, known_face_names = load_all_face_encodings()\n",
    "\n",
    "        if selected_user not in known_face_names:\n",
    "            print(f\"‚ùå No face encoding found for {selected_user}.\")\n",
    "            return\n",
    "\n",
    "        voice_match = recognize_voice(selected_user)\n",
    "        if not voice_match:\n",
    "            print(\"‚ùå Voice authentication failed.\")\n",
    "            return\n",
    "        print(\"‚úÖ Voice matched. Please look at the camera...\")\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(3, 640)\n",
    "        cap.set(4, 480)\n",
    "        time.sleep(1)\n",
    "        authenticated = False\n",
    "        last_frame = None\n",
    "        timeout = time.time() + 20\n",
    "\n",
    "        while time.time() < timeout:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: continue\n",
    "            small = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "            rgb = cv2.cvtColor(small, cv2.COLOR_BGR2RGB)\n",
    "            locs = face_recognition.face_locations(rgb)\n",
    "            if len(locs) == 1:\n",
    "                enc = face_recognition.face_encodings(rgb, locs)[0]\n",
    "                idx = known_face_names.index(selected_user)\n",
    "                dist = face_recognition.face_distance([known_face_encodings[idx]], enc)[0]\n",
    "                top, right, bottom, left = [v * 4 for v in locs[0]]\n",
    "                color = (0, 255, 0) if dist < 0.5 else (0, 0, 255)\n",
    "                label = f\"{selected_user} ‚úÖ\" if dist < 0.5 else f\"{selected_user} ‚ùå\"\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), color, 2)\n",
    "                cv2.putText(frame, label, (left, bottom - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                authenticated = dist < 0.5\n",
    "                last_frame = frame.copy()\n",
    "                if authenticated:\n",
    "                    break\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow(rgb_frame)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "        cap.release()\n",
    "        clear_output(wait=True)\n",
    "        if authenticated:\n",
    "            print(f\"‚úÖ Authentication successful for {selected_user}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Authentication failed for {selected_user}\")\n",
    "        if last_frame is not None:\n",
    "            plt.imshow(cv2.cvtColor(last_frame, cv2.COLOR_BGR2RGB))\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Final Frame\")\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "# ========== Button Bindings ==========\n",
    "add_user_button.on_click(on_add_user)\n",
    "delete_user_button.on_click(on_delete_user)\n",
    "update_user_button.on_click(on_update_user)\n",
    "view_user_button.on_click(on_view_user)\n",
    "refresh_button.on_click(refresh_user_list)\n",
    "authenticate_button.on_click(authenticate_user)\n",
    "\n",
    "\n",
    "# ========== Admin UI ==========\n",
    "admin_panel = VBox([\n",
    "    Label(\"üîê Admin Panel for Biometric Authentication System\"),\n",
    "    HBox([new_user_text, add_user_button, delete_user_button, update_user_button]),\n",
    "    HBox([user_dropdown, view_user_button, authenticate_button, refresh_button]),\n",
    "    output\n",
    "])\n",
    "\n",
    "display(admin_panel)\n",
    "refresh_user_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d03b6-3b36-4a07-8b59-b5d7f22e10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde0ec2-fae3-4aaf-94c2-faad0fbad378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
